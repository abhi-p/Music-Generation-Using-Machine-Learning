{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"first_network_backup.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"EYfTheRzP2zB","colab_type":"code","outputId":"aac4fed4-75e1-453d-c428-15922ac82bcf","executionInfo":{"status":"ok","timestamp":1573683154804,"user_tz":300,"elapsed":56844,"user":{"displayName":"Romal Peccia","photoUrl":"","userId":"02582866957119773670"}},"colab":{"base_uri":"https://localhost:8080/","height":189}},"source":["!pip install pypianoroll\n","!pip install mido\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import mido\n","import pypianoroll\n","import matplotlib.pyplot as plt\n","from pypianoroll import Multitrack, Track\n","import pretty_midi as pmidi\n","import os\n","import numpy as np\n","import time\n","\n","from google.colab import drive \n","drive.mount('/content/drive', force_remount= True)\n","\n","\n","drive_path    = 'drive/My Drive/Capstone - ECE496/'\n","data_in_path  = 'midi/'\n","output_path ='out_midi/'\n","\n","midi_dir = drive_path + data_in_path\n","out_dir = drive_path + output_path"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting pypianoroll\n","  Downloading https://files.pythonhosted.org/packages/1c/ea/99a078d44089f1c7a062d5ec500e393bbd75958e513a7391d821bfddc05b/pypianoroll-0.5.2.tar.gz\n","Requirement already satisfied: six<2.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pypianoroll) (1.12.0)\n","Requirement already satisfied: numpy<2.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pypianoroll) (1.17.4)\n","Requirement already satisfied: scipy<2.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pypianoroll) (1.3.2)\n","Requirement already satisfied: pretty_midi<1.0,>=0.2.8 in /usr/local/lib/python3.6/dist-packages (from pypianoroll) (0.2.8)\n","Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.6/dist-packages (from pretty_midi<1.0,>=0.2.8->pypianoroll) (1.2.6)\n","Building wheels for collected packages: pypianoroll\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BNbEeplsvCkH","colab_type":"code","outputId":"5391f959-87bc-49ce-d163-0572803c53f5","executionInfo":{"status":"error","timestamp":1573758593222,"user_tz":300,"elapsed":801,"user":{"displayName":"Romal Peccia","photoUrl":"","userId":"02582866957119773670"}},"colab":{"base_uri":"https://localhost:8080/","height":239}},"source":["#TODO extract and store tempo information?\n","# ValueError: Cannot get beat timings to quantize pianoroll. on iteration ~3000\n","#issue in either pypianoroll.parse_midi or pypianoroll.write\n","'''\n","list entire directory\n","get unique file #s ->xxx.xxx.midi\n","load pairs of files into lists of tuples\n","'''\n","\n","max_counter=3\n","counter=0\n","\n","#contains an array of tuples(input, target)\n","tupleArr=[]\n","\n","#contains a 2 element tuple, converted into tuple type later\n","tuple_list=[]\n","\n","dir_path = \"drive/My Drive/Capstone - ECE496/single_note_random_split\"\n","dir_files = os.listdir(dir_path)\n","dir_files.sort()\n","current_song=\"\"\n","\n","for midi_file_num in dir_files:\n","  '''\n","  #extract tempo\n","  song_tempo = 0\n","  test_file = mido.MidiFile(dir_path +\"/\" + midi_file_num)\n","  for msg in test_file:\n","    if msg.is_meta:\n","        split = str(msg).split()\n","        if 'set_tempo' in split:\n","            song_tempo = int(mido.tempo2bpm(int(split[3].split('=')[1]))) #mido uses tempo in ms/beat but pypianoroll uses beat/min as tempo\n","            break\n","  '''\n","  '''\n","  if bad_list:\n","    if midi_file_num in bad_list:\n","        pproll = pypianoroll.parse(dir_path + \"/\" + midi_file_num)\n","        print(midi_file_num, len(pproll.tracks[0].pianoroll))\n","  '''\n","  #set flag to false at beginning of each iteration\n","  new_song = False\n","\n","  #checks if we are in a new song or current song\n","  if(current_song != midi_file_num.split(\".\")[0]):\n","    new_song = True\n","    current_song = midi_file_num.split(\".\")[0]\n","\n","  #gets the current song interval part  \n","  current_part = midi_file_num.split(\".\")[1]\n","\n","  #if in a new song, reset variables\n","  if new_song:\n","    index=0\n","    tuple_list=[]\n","\n","\n","  \n","  #add element to tuple\n","  pproll = None\n","  pproll = pypianoroll.parse(dir_path + \"/\" + midi_file_num)\n","  pproll.name = midi_file_num\n","  #to indicate timesteps with no note on\n","  for i in range(len(pproll.tracks)): #iterate over tracks\n","    for j in range(len(pproll.tracks[i].pianoroll)): #iterate over timesteps\n","      for k in range(len(pproll.tracks[i].pianoroll[j])): #iterate over notes\n","        if pproll.tracks[i].pianoroll[j][k] != 0:\n","          pproll.tracks[i].pianoroll[j][k] = 1\n","      if 1 not in pproll.tracks[i].pianoroll[j]:\n","          pproll.tracks[i].pianoroll[j][0] = 1 #TODO make this less sketchy, setting index 0 = 1 to represent no notes on\n","\n","  tuple_list.append(pproll)\n","\n","  #if tuple(input, target) complete, add to array of tuples, reset vars\n","  if(index != 1):\n","    index=index+1\n","  elif(index ==1):\n","\n","    #tuple has both input and target now\n","    t = tuple(tuple_list)\n","    #print(t)\n","    tupleArr.append(t)\n","\n","    #reset and add initial element to tuple\n","    tuple_list = []\n","    pproll = None\n","    pproll = pypianoroll.parse(dir_path + \"/\" + midi_file_num)\n","    pproll.name = midi_file_num\n","    \n","    #to indicate timesteps with no note on\n","    for i in range(len(pproll.tracks)): #iterate over tracks\n","      for j in range(len(pproll.tracks[i].pianoroll)): #iterate over timesteps\n","        for k in range(len(pproll.tracks[i].pianoroll[j])): #iterate over notes\n","            if pproll.tracks[i].pianoroll[j][k] != 0:\n","              pproll.tracks[i].pianoroll[j][k] = 1\n","        if 1 not in pproll.tracks[i].pianoroll[j]:\n","            pproll.tracks[i].pianoroll[j][0] = 1 #TODO make this less sketchy, setting index 0 = 1 to represent no notes on\n","\n","    tuple_list.append(pproll)\n","\n","  if(counter == max_counter):\n","    break\n","  if (counter%100 == 0):\n","    print(counter)\n","  counter = counter+1\n","  \n","train_data=tupleArr\n","data_pairs= []\n","tuple_list=[]\n","time_factor = 10\n","for pair in train_data:\n","  assert(pair[0].tracks[0].pianoroll.shape[0]==pair[1].tracks[0].pianoroll.shape[0])\n","  time_steps= pair[0].tracks[0].pianoroll.shape[0]\n","  input_matrix=np.empty([time_steps,25])\n","  target_matrix=np.empty([time_steps,25])\n","  for time_step in range(time_steps):\n","    input_matrix[time_step][0]=((pair[0].tracks[0].pianoroll)[time_step][0])\n","    input_matrix[time_step][1:25]=((pair[0].tracks[0].pianoroll)[time_step][48:72])\n","    target_matrix[time_step][0]=((pair[1].tracks[0].pianoroll)[time_step][0])\n","    target_matrix[time_step][1:25]=((pair[1].tracks[0].pianoroll)[time_step][48:72])\n","\t\n","  reduced_time = int(time_steps/time_factor)\n","  input_matrix = input_matrix[time_steps-reduced_time : ]\n","  print(len(input_matrix))\n","  print(torch.argmax(torch.tensor(input_matrix), dim = 1))\n","  target_matrix = target_matrix[  : reduced_time]\n","  print(len(target_matrix))\n","  print(torch.argmax(torch.tensor(target_matrix), dim = 1))\n","  tuple_list.append(input_matrix)\n","  tuple_list.append(target_matrix)\n","  data_pairs.append(tuple(tuple_list))\n","#print(tupleArr)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-bd14bb04ffda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"drive/My Drive/Capstone - ECE496/single_note_random_split\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdir_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdir_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mcurrent_song\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}]},{"cell_type":"code","metadata":{"id":"ei00a97rradH","colab_type":"code","outputId":"e8291423-e873-4491-ca2b-62324328b92a","executionInfo":{"status":"ok","timestamp":1573684756310,"user_tz":300,"elapsed":532,"user":{"displayName":"Romal Peccia","photoUrl":"","userId":"02582866957119773670"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["#debugging length of pianoroll mismatches between melody and extension\n","print(len(tupleArr))\n","bad_list = []\n","for i in range(len(tupleArr)):\n","    t = tupleArr[i]\n","    mel = t[0].tracks[0].pianoroll\n","    ext = t[1].tracks[0].pianoroll\n","    if (len(mel) != len(ext)):\n","        #print(i, len(mel), len(ext))\n","        #print(t[0].name, t[1].name)\n","        #print(len(mel), len(ext))\n","        bad_list.append(t[0].name)\n","        tupleArr.remove(tupleArr[i])\n","print(bad_list)\n","print(len(tupleArr), len(bad_list))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3\n","[]\n","3 0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nN2dpOYIJNXu","colab_type":"code","colab":{}},"source":["#debugging setting timestep of 0s to 1 \n","print(len(tupleArr))\n","tupleArr = tupleArr[0:10]\n","for i in range(len(tupleArr)):\n","    print(\"index\", i)\n","    t = tupleArr[i][0].tracks[0].pianoroll\n","    for j in t:\n","        for k in range(len(j)):\n","            if j[k] == 1 and k > 100 :\n","                print (k)\n","for t in tupleArr:\n","    tens = torch.tensor(t[0].tracks[0].pianoroll)\n","    print(tens.shape)\n","    print(tens)\n","    amax = torch.argmax(tens, dim = 1)\n","    print(amax.shape)\n","    print(amax)\n","    break\n","#argmax is returning 127 when it doesnt find a max, but it should always be finding one (oops i missed a couple lines of code in the tupleArr logic)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPIq1RT8bk3Z","colab_type":"code","colab":{}},"source":["class SingleNoteRNN(nn.Module):\n","    def __init__(self, hidden_size, vocab_size = 128, n_layers = 1):\n","        super(SingleNoteRNN, self).__init__()\n","        self.vocab_size = vocab_size\n","        self.rnn = nn.GRU(vocab_size, hidden_size, n_layers, batch_first=True)\n","        self.decoder = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, data, hidden = None):\n","        output, hidden = self.rnn(data, hidden) # get the next output and hidden state\n","        output = self.decoder(output)          # predict distribution over next tokens\n","        output = self.ReLU(output)\n","        return output, hidden\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZWkeMnuQb94u","colab_type":"code","outputId":"144034c8-a591-48ad-8a9f-0e2c23321f6f","executionInfo":{"status":"error","timestamp":1573686620098,"user_tz":300,"elapsed":456,"user":{"displayName":"Romal Peccia","photoUrl":"","userId":"02582866957119773670"}},"colab":{"base_uri":"https://localhost:8080/","height":132}},"source":["def accuracy(model_output, truth):\n","    #if (len(model_output) != len(truth)):\n","    #    assert(\"error: size mismatch: model_output vs truth\")\n","    #else:\n","    print(model_output.shape, truth.shape)\n","    preds = torch.argmax(model_output, dim = 2)\n","    correct = int((torch.eq(pred, truth)).sum())\n","    #print(preds)\n","    #print(truth)\n","    return \n","\n","def train_SNRNN(model, train_data, val_data = None, epochs = 10, batch_size = 64, learning_rate = 1e-3):\n","    train_loss_list, val_loss_list, train_acc_list, val_acc_list = [],[],[],[]\n","    \n","    criterion = nn.CrossEntropyLoss() #.cuda()\n","    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 1e-5)\n","    \n","    for epoch in range(0, epochs):\n","        epoch_time = time.time()\n","        epoch_loss = 0\n","        epoch_correct = 0\n","        epoch_total = 0\n","        for pair in train_data:\n","          input =  torch.tensor(pair[0].tracks[0].pianoroll).unsqueeze(0).float()\n","          target = torch.tensor(pair[1].tracks[0].pianoroll).unsqueeze(0).float()\n","          target = torch.argmax(target, dim=2)\n","          \n","          optimizer.zero_grad()\n","          output, hidden = model(input)\n","          loss = criterion(output.reshape(1, input.shape[2], -1), target)\n","          loss.backward()\n","          optimizer.step()\n","\n","          #calculate accuracy\n","          pred = torch.argmax(output, dim = 2)\n","          print(pred, target)\n","          time.sleep(2)\n","          for i in range(len(pred.reshape(-1))):\n","              if int(pred.reshape(-1)[i]) == int( target.reshape(-1)[i]):\n","                  epoch_correct +=1\n","          #epoch_correct += int((torch.eq(pred.reshape(-1), target.reshape(-1))).sum())\n","          epoch_total += pred.shape[1]\n","\n","          epoch_loss += float(loss)\n","          \n","        #print(epoch_correct, epoch_total)\n","        epoch_accuracy = (epoch_correct/epoch_total)*100\n","        print(epoch, int(time.time()-epoch_time), \"s :loss:\", epoch_loss, \"accuracy\", epoch_accuracy)\n","        train_loss_list.append(epoch_loss)\n","        train_acc_list.append(epoch_loss)\n","\n","\n","    \n","    return train_loss_list, val_loss_list, train_acc_list, val_acc_list\n","    \n","model = SingleNoteRNN( 256)\n","train_loss_list, val_loss_list, train_acc_list, val_acc_list = train_SNRNN(model, tupleArr, epochs = 500, learning_rate = 1e-2)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-58-db8dca029c83>\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    output, hidden2 = model(target), hidden1)\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"uqcY2S4687S7","colab_type":"code","outputId":"6ae72068-ba07-4724-acbf-785e9a2828a7","executionInfo":{"status":"error","timestamp":1573686990697,"user_tz":300,"elapsed":20422,"user":{"displayName":"Romal Peccia","photoUrl":"","userId":"02582866957119773670"}},"colab":{"base_uri":"https://localhost:8080/","height":441}},"source":["#testing concatenation\n","def accuracy(model_output, truth):\n","    #if (len(model_output) != len(truth)):\n","    #    assert(\"error: size mismatch: model_output vs truth\")\n","    #else:\n","    print(model_output.shape, truth.shape)\n","    preds = torch.argmax(model_output, dim = 2)\n","    correct = int((torch.eq(pred, truth)).sum())\n","    #print(preds)\n","    #print(truth)\n","    return \n","\n","def train_SNRNN(model, train_data, val_data = None, epochs = 10, batch_size = 64, learning_rate = 1e-3):\n","    train_loss_list, val_loss_list, train_acc_list, val_acc_list = [],[],[],[]\n","    \n","    criterion = nn.CrossEntropyLoss() #.cuda()\n","    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 1e-5)\n","    \n","    for epoch in range(0, epochs):\n","        epoch_time = time.time()\n","        epoch_loss = 0\n","        epoch_correct = 0\n","        epoch_total = 0\n","        input_matrix=np.empty([600,25])\n","        target_matrix=np.empty([600,25])\n","        for pair in train_data:\n","\n","          for cat in range(0,pair[0].tracks[0].pianoroll.shape[0]):\n","            input_matrix[cat][0]=((pair[0].tracks[0].pianoroll)[cat][0])\n","            input_matrix[cat][1:25]=((pair[0].tracks[0].pianoroll)[cat][47:71])\n","            target_matrix[cat][0]=((pair[1].tracks[0].pianoroll)[cat][0])\n","            target_matrix[cat][1:25]=((pair[1].tracks[0].pianoroll)[cat][47:71])\n","          \n","          \n","          input =  torch.tensor(input_matrix).unsqueeze(0).float()         \n","          target_one_hot = torch.tensor(target_matrix).unsqueeze(0).float()\n","          target = torch.argmax(target_one_hot, dim=2)\n","\n","          optimizer.zero_grad()\n","          output1, hidden1 = model(input)\n","          #print(output1.reshape(1, input.shape[2], -1).shape, target.shape)\n","          output, hidden2 = model(target_one_hot, hidden1)\n","          loss = criterion(output.reshape(1, input.shape[2], -1), target)\n","          loss.backward()\n","          optimizer.step()\n","\n","          #calculate accuracy\n","          pred = torch.argmax(output, dim = 2)\n","          #print(pred, target)\n","          #time.sleep(2)\n","          for i in range(len(pred.reshape(-1))):\n","              if int(pred.reshape(-1)[i]) == int( target.reshape(-1)[i]):\n","                  epoch_correct +=1\n","          #epoch_correct += int((torch.eq(pred.reshape(-1), target.reshape(-1))).sum())\n","          epoch_total += pred.shape[1]\n","\n","          epoch_loss += float(loss)\n","\n","        #print(epoch_correct, epoch_total)\n","        epoch_accuracy = (epoch_correct/epoch_total)*100\n","        print(epoch, int(time.time()-epoch_time), \"s :loss:\", epoch_loss, \"accuracy\", epoch_accuracy)\n","        train_loss_list.append(epoch_loss)\n","        train_acc_list.append(epoch_loss)\n","\n","\n","    \n","    return train_loss_list, val_loss_list, train_acc_list, val_acc_list\n","    \n","model = SingleNoteRNN( 256, vocab_size = 25)\n","train_loss_list, val_loss_list, train_acc_list, val_acc_list = train_SNRNN(model, tupleArr, epochs = 100, learning_rate = 0.5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0 3 s :loss: 16.063558101654053 accuracy 7.277777777777778\n","1 2 s :loss: 13.69808316230774 accuracy 1.8333333333333333\n","2 3 s :loss: 14.763806819915771 accuracy 1.8333333333333333\n","3 3 s :loss: 21.548787117004395 accuracy 1.8333333333333333\n","4 3 s :loss: 12.230830907821655 accuracy 1.8333333333333333\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-eebc0e8247e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleNoteRNN\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_SNRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtupleArr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-64-eebc0e8247e7>\u001b[0m in \u001b[0;36mtrain_SNRNN\u001b[0;34m(model, train_data, val_data, epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     41\u001b[0m           \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"M21UFZQMAfTx","colab_type":"code","outputId":"caab0c90-e979-4834-af32-3c96f89e2a65","colab":{"base_uri":"https://localhost:8080/","height":503}},"source":["# plotting\n","plt.title(\"Training Curve\")\n","plt.plot(train_loss_list, label=\"Train\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.show()\n","\n","plt.title(\"Training Curve\")\n","plt.plot(epochs, train_acc_list, label=\"Train\")\n","plt.plot(epochs, val_acc_list, label=\"Validation\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend(loc='best')\n","plt.show()\n","\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-129-a40d1ea3eaa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Curve\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_loss_list' is not defined"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwJPS7t3WAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}